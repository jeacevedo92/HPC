{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Objective </span>\n",
    "\n",
    "- To learn how to overlap data transfer with computation\n",
    "    - Asynchronous data transfer in CUDA\n",
    "    - Practical limitations of CUDA streams\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Simple Multi-Stream Host Code </span>\n",
    "\n",
    "```cpp\n",
    "\n",
    "cudaStream_t stream0, stream1;\n",
    "cudaStreamCreate(&stream0);\n",
    "cudaStreamCreate(&stream1);\n",
    "float *d_A0, *d_B0, *d_C0; // device memory for stream 0\n",
    "float *d_A1, *d_B1, *d_C1; // device memory for stream 1\n",
    "// cudaMalloc() calls for d_A0, d_B0, d_C0, d_A1, d_B1, d_C1 go here\n",
    "\n",
    "```\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Simple Multi-Stream Host Code (Cont.) </span>\n",
    "\n",
    "```cpp\n",
    "\n",
    "for (int i=0; i<n; i+=SegSize*2) {\n",
    "    cudaMemcpyAsync(d_A0, h_A+i, SegSize*sizeof(float),..., stream0);\n",
    "    cudaMemcpyAsync(d_B0, h_B+i, SegSize*sizeof(float),..., stream0);\n",
    "    vecAdd<<<SegSize/256, 256, 0, stream0>>>(d_A0, d_B0,...);\n",
    "    cudaMemcpyAsync(h_C+i, d_C0, SegSize*sizeof(float),..., stream0);\n",
    "    cudaMemcpyAsync(d_A1, h_A+i+SegSize, SegSize*sizeof(float),..., stream1);\n",
    "    cudaMemcpyAsync(d_B1, h_B+i+SegSize, SegSize*sizeof(float),..., stream1);\n",
    "    vecAdd<<<SegSize/256, 256, 0, stream1>>>(d_A1, d_B1, ...);\n",
    "    cudaMemcpyAsync(d_C1, h_C+i+SegSize, SegSize*sizeof(float),..., stream1);\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> A View Closer to Reality </span>\n",
    "\n",
    "![alt tag](img/5.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Not quite the overlap we want in some GPUs </span>\n",
    "\n",
    "- C.0 blocks A.1 and B.1 in the copy engine queue\n",
    "\n",
    "![alt tag](img/6.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Better Multi-Stream Host Code </span>\n",
    "\n",
    "```cpp\n",
    "\n",
    "for (int i=0; i<n; i+=SegSize*2) {\n",
    "    cudaMemcpyAsync(d_A0, h_A+i, SegSize*sizeof(float),..., stream0);\n",
    "    cudaMemcpyAsync(d_B0, h_B+i, SegSize*sizeof(float),..., stream0);\n",
    "    cudaMemcpyAsync(d_A1, h_A+i+SegSize, SegSize*sizeof(float),..., stream1);\n",
    "    cudaMemcpyAsync(d_B1, h_B+i+SegSize, SegSize*sizeof(float),..., stream1);\n",
    "    vecAdd<<<SegSize/256, 256, 0, stream0>>>(d_A0, d_B0, ...);\n",
    "    vecAdd<<<SegSize/256, 256, 0, stream1>>>(d_A1, d_B1, ...);\n",
    "    cudaMemcpyAsync(h_C+i, d_C0, SegSize*sizeof(float),..., stream0);\n",
    "    cudaMemcpyAsync(h_C+i+SegSize, d_C1, SegSize*sizeof(float),..., stream1);\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> C.0 no longer blocks A.1 and B.1 </span>\n",
    "\n",
    "![alt tag](img/8.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Better, not quite the best overlap </span>\n",
    "\n",
    "- C.1 blocks next iteration A.0 and B.0 in the copy engine queue\n",
    "\n",
    "![alt tag](img/3.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Ideal, Pipelined Timing </span>\n",
    "\n",
    "- Will need at least three buffers for each original A, B, and C, code is more complicated (see Lab assignment description)\n",
    "\n",
    "![alt tag](img/10.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Hyper Queues </span>\n",
    "\n",
    "- Provide multiple queues for each engine\n",
    "- Allow more concurrency by allowing some streams to make progress for an engine while others are blocked\n",
    "\n",
    "![alt tag](img/11.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Wait until all tasks have completed </span>\n",
    "\n",
    "- ```cudaStreamSynchronize(stream_id)```\n",
    "    - Used in host code\n",
    "    - Takes one parameter â€“ stream identifier\n",
    "    - Wait until all tasks in a stream have completed\n",
    "    - E.g., ```cudaStreamSynchronize(stream0)``` in host code ensures that all tasks in the queues of stream0 have completed\n",
    "\n",
    "- This is different from ```cudaDeviceSynchronize()```\n",
    "    - Also used in host code\n",
    "    - No parameter\n",
    "    - ```cudaDeviceSynchronize()``` waits until all tasks in all streams have completed for the current device\n",
    "\n",
    "![alt tag](img/3.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer>\n",
    "<cite> GPU NVIDIA Teaching Kit - University of Illinois </cite>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
