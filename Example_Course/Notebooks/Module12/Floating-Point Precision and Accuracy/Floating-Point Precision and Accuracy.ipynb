{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Objective </span>\n",
    "\n",
    "- To understand the fundamentals of floating-point representation\n",
    "- To understand the IEEE-754 Floating Point Standard\n",
    "- CUDA GPU Floating-point speed, accuracy and precision\n",
    "    - Cause of errors\n",
    "    - Algorithm considerations\n",
    "    - Deviations from IEEE-754\n",
    "    - Accuracy of device runtime functions\n",
    "    - -fastmath compiler option\n",
    "    - Future performance considerations\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> What is IEEE floating-point format? </span>\n",
    "\n",
    "\n",
    "![alt tag](img/3.png)\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Normalized Representation </span>\n",
    "\n",
    "![alt tag](img/4.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Exponent Representation </span>\n",
    "\n",
    "![alt tag](img/5.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> A simple, hypothetical 5-bit FP format </span>\n",
    "\n",
    "![alt tag](img/6.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Representable Numbers </span>\n",
    "\n",
    "![alt tag](img/7.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Representable Numbers of a 5-bit Hypothetical IEEE Format </span>\n",
    "\n",
    "![alt tag](img/8.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Flush to Zero </span>\n",
    "\n",
    "- Treat all bit patterns with E=0 as 0.0\n",
    "    - This takes away several representable numbers near zero and lump them all into 0.0\n",
    "    - For a representation with large M, a large number of representable numbers will be removed\n",
    "\n",
    "![alt tag](img/9.png)\n",
    "\n",
    "![alt tag](img/10.png)\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Why is flushing to zero problematic? </span>\n",
    "\n",
    "- Many physical model calculations work on values that are very close to zero\n",
    "    - Dark (but not totally black) sky in movie rendering\n",
    "    - Small distance fields in electrostatic potential calculation\n",
    "    - ...\n",
    "- Without Denormalization, these calculations tend to create artifacts that compromise the integrity of the models\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Denormalized Numbers </span>\n",
    "\n",
    "- The actual method adopted by the IEEE standard is called “denormalized numbers” or “gradual underflow”.\n",
    "    - The method relaxes the normalization requirement for numbers very close to 0.\n",
    "    - Whenever E=0, the mantissa is no longer assumed to be of the form 1.XX. Rather, it is assumed to be 0.XX. In general, if the n-bit exponent is 0, the value is 0.M * 2 - 2 ^(n-1) + 2\n",
    "\n",
    "![alt tag](img/12.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Denormalization </span>\n",
    "\n",
    "![alt tag](img/13.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> IEEE 754 Format and Precision </span>\n",
    "\n",
    "- Single Precision\n",
    "    - 1-bit sign, 8 bit exponent (bias-127 excess), 23 bit fraction\n",
    "- Double Precision\n",
    "    - 1-bit sign, 11-bit exponent (1023-bias excess), 52 bit fraction\n",
    "    - The largest error for representing a number is reduced to 1/229 of single precision representation\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Special Bit Patterns </span>\n",
    "\n",
    "![alt tag](img/15.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Floating Point Accuracy and Rounding </span>\n",
    "\n",
    "- The accuracy of a floating point arithmetic operation is measured by the maximal error introduced by the operation.\n",
    "- The most common source of error in floating point arithmetic is when the operation generates a result that cannot be exactly represented and thus requires rounding.\n",
    "- Rounding occurs if the mantissa of the result value needs too many bits to be represented exactly.\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Rounding and Error </span>\n",
    "\n",
    "![alt tag](img/17.png)\n",
    "\n",
    "\n",
    "\n",
    "![alt tag](img/18.png)\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Error Measure </span>\n",
    "\n",
    "- If a hardware adder has at least two more bit positions than the total (both implicit and explicit) number of mantissa bits, the error would never be more than half of the place value of the mantissa\n",
    "    - 0.001 in our 5-bit format\n",
    "- We refer to this as 0.5 ULP (Units in the Last Place)\n",
    "    - If the hardware is designed to perform arithmetic and rounding operations perfectly, the most error that one should introduce should be no more than 0.5 ULP\n",
    "    - The error is limited by the precision for this case\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Order of Operations Matter </span>\n",
    "\n",
    "- Floating point operations are not strictly associative\n",
    "- The root cause is that some times a very small number can disappear when added to or subtracted from a very large number.\n",
    "    - (Large + Small) + Small ≠ Large + (Small + Small)\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Algorithm Considerations </span>\n",
    "\n",
    "![alt tag](img/21.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Runtime Math Library </span>\n",
    "\n",
    "![alt tag](img/22.png)\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Make your program float-safe! </span>\n",
    "\n",
    "- Newer GPU hardware has double precision support\n",
    "    - Double precision will have additional performance cost\n",
    "    - Careless use of double or undeclared types may run more slowly\n",
    "- Important to be float-safe (be explicit whenever you want single precision) to avoid using double precision where it is not needed\n",
    "    - Add ‘f’ specifier on float literals:\n",
    "    ```cpp\n",
    "        - foo = bar * 0.123; // double assumed\n",
    "        - foo = bar * 0.123f; // float explicit\n",
    "    ```\n",
    "    \n",
    "    - Use float version of standard library functions\n",
    "    ```cpp\n",
    "        - foo = sin(bar); // double assumed\n",
    "        - foo = sinf(bar); // single precision explicit\n",
    "    ```\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> CUDA Deviations from IEEE-754 </span>\n",
    "\n",
    "- Addition and multiplication are IEEE 754 compliant\n",
    "     - Maximum 0.5 ulp (units in the least place) error\n",
    "- Division accuracy is not fully compliant (2 ulp)\n",
    "- Not all rounding modes are supported\n",
    "- No mechanism to detect floating-point exceptions (yet)\n",
    "\n",
    "<hr style=\"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<footer>\n",
    "<cite> GPU NVIDIA Teaching Kit - University of Illinois </cite>\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
